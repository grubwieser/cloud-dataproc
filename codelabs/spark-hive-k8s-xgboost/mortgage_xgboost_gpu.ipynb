{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2020 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: scikit-learn in /opt/conda/anaconda/lib/python3.6/site-packages (0.23.1)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /opt/conda/anaconda/lib/python3.6/site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /opt/conda/anaconda/lib/python3.6/site-packages (from scikit-learn) (1.14.3)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /opt/conda/anaconda/lib/python3.6/site-packages (from scikit-learn) (2.0.0)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /opt/conda/anaconda/lib/python3.6/site-packages (from scikit-learn) (0.15.1)\n"
     ]
    }
   ],
   "source": [
    "# Install the latest version of scikit-learn and restart kernel\n",
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mortgage XGboost - GPUs \n",
    "\n",
    "Based on notebooks from https://github.com/rapidsai/spark-examples\n",
    "\n",
    "Learn more about RAPIDS-Spark XGboost4j here https://news.developer.nvidia.com/gpu-accelerated-spark-xgboost/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Include pyspark methods used in notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.types import FloatType, IntegerType, StructField, StructType\n",
    "from pyspark.sql.functions import col\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data using GPU data reader\n",
    "\n",
    "This is a custom built reader created by Nvida to read data using GPUs. \n",
    "\n",
    "In Spark 2.4 you need include the GpuDataReader method but from Spark 3.0+ you will be able to use the native Spark read method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml.dmlc.xgboost4j.scala.spark import XGBoostClassificationModel, XGBoostClassifier\n",
    "from ml.dmlc.xgboost4j.scala.spark.rapids import GpuDataReader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set label used for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'delinquency_12'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a list of the features used for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['orig_channel',\n",
       " 'first_home_buyer',\n",
       " 'loan_purpose',\n",
       " 'property_type',\n",
       " 'occupancy_status',\n",
       " 'property_state',\n",
       " 'product_type',\n",
       " 'relocation_mortgage_indicator',\n",
       " 'seller_name',\n",
       " 'mod_flag',\n",
       " 'orig_interest_rate',\n",
       " 'orig_upb',\n",
       " 'orig_loan_term',\n",
       " 'orig_ltv',\n",
       " 'orig_cltv',\n",
       " 'num_borrowers',\n",
       " 'dti',\n",
       " 'borrower_credit_score',\n",
       " 'num_units',\n",
       " 'zip',\n",
       " 'mortgage_insurance_percent',\n",
       " 'current_loan_delinquency_status',\n",
       " 'current_actual_upb',\n",
       " 'interest_rate',\n",
       " 'loan_age',\n",
       " 'msa',\n",
       " 'non_interest_bearing_upb']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = StructType([\n",
    "    StructField('orig_channel', FloatType()),\n",
    "    StructField('first_home_buyer', FloatType()),\n",
    "    StructField('loan_purpose', FloatType()),\n",
    "    StructField('property_type', FloatType()),\n",
    "    StructField('occupancy_status', FloatType()),\n",
    "    StructField('property_state', FloatType()),\n",
    "    StructField('product_type', FloatType()),\n",
    "    StructField('relocation_mortgage_indicator', FloatType()),\n",
    "    StructField('seller_name', FloatType()),\n",
    "    StructField('mod_flag', FloatType()),\n",
    "    StructField('orig_interest_rate', FloatType()),\n",
    "    StructField('orig_upb', IntegerType()),\n",
    "    StructField('orig_loan_term', IntegerType()),\n",
    "    StructField('orig_ltv', FloatType()),\n",
    "    StructField('orig_cltv', FloatType()),\n",
    "    StructField('num_borrowers', FloatType()),\n",
    "    StructField('dti', FloatType()),\n",
    "    StructField('borrower_credit_score', FloatType()),\n",
    "    StructField('num_units', IntegerType()),\n",
    "    StructField('zip', IntegerType()),\n",
    "    StructField('mortgage_insurance_percent', FloatType()),\n",
    "    StructField('current_loan_delinquency_status', IntegerType()),\n",
    "    StructField('current_actual_upb', FloatType()),\n",
    "    StructField('interest_rate', FloatType()),\n",
    "    StructField('loan_age', FloatType()),\n",
    "    StructField('msa', FloatType()),\n",
    "    StructField('non_interest_bearing_upb', FloatType()),\n",
    "    StructField(label, IntegerType()),\n",
    "])\n",
    "\n",
    "features = [ x.name for x in schema if x.name != label ]\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set GCS bucket used for data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcs_bucket = 'gs://cloudml-demo-datalake'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read training data parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ml.dmlc.xgboost4j.scala.spark.rapids.GpuDataset at 0x7fbe0de412e8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_url_parquet_file = f'{gcs_bucket}/processed/parquet/mortgage_small_train/*.parquet'\n",
    "train_data = GpuDataReader(spark).parquet(train_url_parquet_file)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read eval data parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ml.dmlc.xgboost4j.scala.spark.rapids.GpuDataset at 0x7fbe0de41518>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_url_parquet_file = f'{gcs_bucket}/processed/parquet/mortgage_small_eval/*.parquet'\n",
    "eval_data = GpuDataReader(spark).parquet(eval_url_parquet_file)\n",
    "eval_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a XGBoostClassifier\n",
    "\n",
    "Full list of available [XGboost parameters](https://xgboost.readthedocs.io/en/latest/parameter.html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = { \n",
    "#     'eta': 0.1, #learning rate \n",
    "#     'gamma': 0.1,\n",
    "#     'missing': 0.0,\n",
    "#     'treeMethod': 'gpu_hist',\n",
    "#     'maxDepth': 10, \n",
    "#     'maxLeaves': 256,\n",
    "#     'growPolicy': 'depthwise',\n",
    "#     'objective': 'binary:logistic',\n",
    "#     'minChildWeight': 30.0,\n",
    "#     'lambda_': 1.0,\n",
    "#     'scalePosWeight': 2.0,\n",
    "#     'subsample': 1.0,\n",
    "#     'nthread': 1,\n",
    "#     'numRound': 100,\n",
    "#     'numWorkers': 1,\n",
    "# }\n",
    "\n",
    "params = { \n",
    "    'treeMethod': 'gpu_hist',\n",
    "    'objective': 'binary:logistic'\n",
    "}\n",
    "\n",
    "classifier = XGBoostClassifier(**params).setLabelCol(label).setFeaturesCols(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create reusable benchmark function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def with_benchmark(phrase, action):\n",
    "    start = time()\n",
    "    result = action()\n",
    "    end = time()\n",
    "    print('{} takes {} seconds'.format(phrase, round(end - start, 2)))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training takes 12.7 seconds\n"
     ]
    }
   ],
   "source": [
    "model = with_benchmark('Training', lambda: classifier.fit(train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View model stats using PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation takes 0.3 seconds\n",
      "Accuracy is 0.9969984992496248\n"
     ]
    }
   ],
   "source": [
    "accuracy = with_benchmark(\n",
    "    'Evaluation',\n",
    "    lambda: MulticlassClassificationEvaluator().setLabelCol(label).evaluate(result))\n",
    "print('Accuracy is ' + str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View model stats using Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predicitons\n",
    "predictions = model.transform(eval_data).select(\"delinquency_12\", \"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9969984992496248\n",
      "f1: 0.7692307692307693\n",
      "weighted precision: 0.7692307692307693\n",
      "weighted recall: 0.7692307692307693\n",
      "auc: 0.8838600976063211\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score\n",
    "\n",
    "predictions_np = np.array((predictions.collect()))\n",
    "\n",
    "np_acc = accuracy_score(predictions_np[:,0], predictions_np[:,1])\n",
    "np_f1 = f1_score(predictions_np[:,0], predictions_np[:,1])\n",
    "np_precision = precision_score(predictions_np[:,0], predictions_np[:,1])\n",
    "np_recall = recall_score(predictions_np[:,0], predictions_np[:,1])\n",
    "np_auc = roc_auc_score(predictions_np[:,0], predictions_np[:,1])\n",
    "\n",
    "print(\"accuracy:\", np_acc)\n",
    "print(\"f1:\", np_f1)\n",
    "print(\"weighted precision:\", np_precision)\n",
    "print(\"weighted recall:\", np_recall)\n",
    "print(\"auc:\", np_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "\n",
    "Based on code from @Zack Akil's [Precision/Recall Optimisation notebok](https://colab.sandbox.google.com/github/ZackAkil/Hands-on-ML-Precision-Recall-Predicting-Pneumonia-in-X-rays/blob/master/Precision_Recall_Optimisation.ipynb#scrollTo=I4Cg_tubgvUx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import package that will generate the confusion matrix scores\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# import packages that will help display the scores\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Delinquent</th>\n",
       "      <th>Predicted Not Delinquent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actually Delinquent</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actually Not Delinquent</th>\n",
       "      <td>3</td>\n",
       "      <td>1983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Predicted Delinquent  Predicted Not Delinquent\n",
       "Actually Delinquent                        10                         3\n",
       "Actually Not Delinquent                     3                      1983"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix_scores = confusion_matrix(predictions_np[:,0], \n",
    "                                           predictions_np[:,1], \n",
    "                                           labels=[1, 0])\n",
    "\n",
    "# display scores as a heatmap\n",
    "df = pd.DataFrame(confusion_matrix_scores, \n",
    "                  columns = [\"Predicted Delinquent\", \"Predicted Not Delinquent\"],\n",
    "                  index = [\"Actually Delinquent\", \"Actually Not Delinquent\"])\n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Delinquent</th>\n",
       "      <th>Predicted Not Delinquent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actually Delinquent</th>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.230769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actually Not Delinquent</th>\n",
       "      <td>0.001511</td>\n",
       "      <td>0.998489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Predicted Delinquent  Predicted Not Delinquent\n",
       "Actually Delinquent                  0.769231                  0.230769\n",
       "Actually Not Delinquent              0.001511                  0.998489"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix_scores_normalized = confusion_matrix(predictions_np[:,0], \n",
    "                                                     predictions_np[:,1], \n",
    "                                                     labels=[1, 0],\n",
    "                                                     normalize='true')\n",
    "\n",
    "# display scores as a heatmap\n",
    "df_normalize = pd.DataFrame(confusion_matrix_scores_normalized, \n",
    "                  columns = [\"Predicted Delinquent\", \"Predicted Not Delinquent\"],\n",
    "                  index = [\"Actually Delinquent\", \"Actually Not Delinquent\"])\n",
    "\n",
    "df_normalize.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.write().overwrite().save(f'{gcs_bucket}/xgboost/spark/mortgage/model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = XGBoostClassificationModel().load(f'{gcs_bucket}/xgboost/spark/mortgage/model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run predictions on evaluation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation takes 0.87 seconds\n",
      "+--------------+--------------------+--------------------+----------+\n",
      "|delinquency_12|       rawPrediction|         probability|prediction|\n",
      "+--------------+--------------------+--------------------+----------+\n",
      "|           1.0|[0.59753340482711...|[0.64509177207946...|       0.0|\n",
      "|           1.0|[-0.4235294461250...|[0.39567250013351...|       1.0|\n",
      "|           1.0|[-0.4235294461250...|[0.39567250013351...|       1.0|\n",
      "|           1.0|[0.59753340482711...|[0.64509177207946...|       0.0|\n",
      "|           1.0|[0.23389831185340...|[0.55820941925048...|       0.0|\n",
      "|           1.0|[-0.4235294461250...|[0.39567250013351...|       1.0|\n",
      "|           1.0|[-0.4235294461250...|[0.39567250013351...|       1.0|\n",
      "|           1.0|[-0.4235294461250...|[0.39567250013351...|       1.0|\n",
      "|           1.0|[-0.4235294461250...|[0.39567250013351...|       1.0|\n",
      "|           1.0|[-0.4235294461250...|[0.39567250013351...|       1.0|\n",
      "|           1.0|[-0.4235294461250...|[0.39567250013351...|       1.0|\n",
      "|           1.0|[-0.4235294461250...|[0.39567250013351...|       1.0|\n",
      "|           1.0|[-0.4235294461250...|[0.39567250013351...|       1.0|\n",
      "+--------------+--------------------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def transform():\n",
    "    result = loaded_model.transform(eval_data).cache()\n",
    "    result.foreachPartition(lambda _: None)\n",
    "    return result\n",
    "\n",
    "result = with_benchmark('Transformation', transform)\n",
    "result.select(label, 'rawPrediction', 'probability', 'prediction').where(\"delinquency_12 > 0\").show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}